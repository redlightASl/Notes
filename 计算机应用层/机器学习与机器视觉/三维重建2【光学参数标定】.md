# 三维重建2【光学参数标定】

本系列博文旨在构建从底层CMOS传感器硬件到顶层算法的三维重建全栈知识架构，但重点在于图像信号处理和三维重建算法。希望能记录自己在学习三维重建过程中学到的知识，并为各位读者指明学习方向，抛砖引玉。

主要框架参考[Yvon Shong](https://www.zhihu.com/people/yvonshong/posts)和[Wang Hawk](https://www.zhihu.com/people/hawk.wang/columns)的博文撰写，其他参考资料包括《智能传感技术课程PPT》、冈萨雷斯《数字图像处理》

## 与成像有关的重点参数

### 噪声

上一章我们从CCD/CMOS原理到ISP部分都在提噪声，但一直没有对CMOS的噪声进行归类。可以知道，噪声的来源有很多，其中**最重要的来源就是Sensor电路内部**。

![image-20240206230551348](三维重建2【光学参数标定】.assets/image-20240206230551348.png)

如上图所示，**场景辐射通量Φ**即光子辐射通量，它照射到光电二极管上，通过间接带隙半导体（Si）的非竖直跃迁过程产生电子；同时传感器自身因为温度影响会释放出一些电子，它和APS电路漏电流一起构成了**暗电流D**，二者共同提供了APS输出电压。每个APS电压都会被附近的放大器先放大一次，再在读出电路的精密运放中再放大一次；最后的ADC会把模拟电压信号转换成数字信号

我们可以将Sensor内部引入的噪声分成四大部分：

* **光散粒噪声**（光子噪声）：由单位时间内入射光子随机分布引起的噪声
* **暗噪声**：由于暗电流作用导致的噪声
* **读出噪声**：由每个APS的近端放大器和用于处理ISO的精密运放引起的噪声
* **ADC噪声**：由ADC量化误差引入的噪声

#### 光散粒噪声

> 在对光电效应一知半解的人看来，当光电二极管受到恒定光照时每个单位时间接收到的光子数量和激发出的电子数量都是固定的，*实际上并不是这样*

在上一节中，我们提到过在光电二极管中，会出现光电转化随机过程。单位时间内，一个光电二极管接收到的光子数是随机的，光电转化的过程也是随机的，前者的随机性要比后者的随机性更大。这是因为光电转化的过程主要受到硅晶体声子只能与有限数量、固定波长的光子发生吸收碰撞的影响，而在芯片制造过程中会努力避免材料不均匀和出现缺陷的情况，并且效果显著；但对于接收光子数就无法控制了。

可以认为**单个光电二极管**（单个像素）**在曝光期间接收的光子平均数量与曝光时间及光通量成正比**，**作为随机变量的光子数遵循泊松分布**，即
$$
N \sim \pi(\alpha t \Phi)
$$
其中N是光电二极管接收的光子数，π表示泊松分布，α是一个比例系数，t表示曝光时间，Φ是光通量

这种由随机变量引起的波动性在图像上表现为可见的噪声，被称为**光散粒噪声**或**泊松噪声**。遵循泊松分布的随机量均值和方差相等，因此光散粒噪声呈现如下图所示的分布，其均值E(N)越大，方差D(N)越大，曲线覆盖宽度越宽

![v2-de0cc688929f53ac689fc247bf96c955_r](三维重建2【光学参数标定】.assets/v2-de0cc688929f53ac689fc247bf96c955_r.jpg)

这在频谱上呈现为典型的**白噪声**，导致光散粒噪声具有两个明显特点：

* 曝光时间越长或场景光照越强，捕获到的光子数量均值越大，其波动也越大，表现为光子噪声绝对值越大
* 光子数量越多，噪声绝对值越大，但在图像中反而越不明显

直观上看，当画面较暗时，单个像素捕获的光子平均数量少，波动也较小；随着图像变亮，光散粒噪声增加变得明显；但当图像继续变亮时，虽然光子噪声的幅值变大了，但从肉眼上看却变得不明显了。因此**对于比较明亮的场景以及较大尺寸的传感器，光散粒噪声是最主要的噪声来源**

> 信噪比先减小，再增加

#### 暗噪声

之前提到过，CCD/CMOS传感器P衬底中的电子分布是动态且随温度变化的，导致即便在没有接受到光子时，因为温度的影响光电二极管也会释放出电子，这就是光电二极管的**热激发**。

在曝光时间内，热激发电子的数目也是一个符合泊松分布的随机量，用下式描述
$$
N \sim \pi(t D)
$$
其中t是曝光时间，D是当前温度下单位时间内的热电子数量。这个随机量也会导致图像上的噪声，即**热噪声**

在没有光线入射或入射光非常少时，光电二极管不会在其下方势阱中积累电荷，但总会有部分热电子进入势阱，这就让热噪声被引入了电路。热噪声的主要特点有：

* **与温度成指数关系，温度每升高6摄氏度，热噪声的均值扩大一倍**
* **与曝光时间成线性关系，曝光时间越长，热噪声越强**

因此如果要控制乃至消除热噪声，需要：

* **降低Sensor的温度**
* **控制曝光时间在一个较短的值**

当然，还有一个基于ISP的解决方法：首先测量出带有热噪声的图像，保存每个像素对应的黑电平值，并在最终图像中使用**黑电平校正**算法减去噪声值即可

读者可能注意到了，上面所有的噪声都是“热噪声”，但本节的标题是“暗噪声”——实际上暗噪声包含两部分：热噪声和漏电流噪声。

在传统的PPS结构中，CMOS的外部电路都是只有输入端的，很少或根本不会有漏电流反灌进光电二极管或读出电路；但在APS中，我们引入了一个三态门，它是基于一个源极跟随器的（有些实现中还会加入一个传输门），就因为这个源极跟随器，会导致可能存在部分漏电流灌入输出节点。因此暗噪声=热噪声+漏电流引起噪声

不过这对我们处理暗噪声几乎没有影响，因为现代ISP基本都配备了黑电平校正，可以直接通过预标定的暗噪声来滤除其影响

当然，由于光散粒噪声和暗噪声共同作用，传感器像素在进入放大器之前的输出电平就变成了一个随机量。由于两个泊松分布之和也是泊松分布，且其均值是两个泊松分布的均值之和，因此L可以表示为

$$
L \sim \pi(t(\alpha \Phi +D)
$$

其中L表示光电传感器（APS）的输出电平

#### 读出噪声和ADC噪声

读出噪声是信号被“放大”这一过程带来的。

理想的运放相当于做乘法，通过运放的模拟电平应当与像素受到的曝光量（接收光子数）成正比。但实际运放会受到供电电压、制造工艺乃至电路设计影响，出现失真，让原始值偏离与光子数成正比的理想值。

运放电路引入的噪声由两大部分构成：

* **本征噪声**：也被称为电压噪声。由于电子器件的非理想性质引起，与运放的电路设计、工艺实现有关，其在宽频带内存在
* **1/f噪声**：也被称为低频噪声、闪烁噪声或粉色噪声。其功率谱密度随着频率增加而下降，呈现为S(f)=K/f的特性。成因复杂，一种解释是认为它与电子器件中的缺陷和杂质有关，在低频工作下会集中“偶发”暴露出来

> 运放的信噪比反映了读出噪声的大小

被放大的信号还会经过ADC才能被转换成固定的数字值，这个过程会为信号添加**ADC量化噪声**。因为模拟电平值是连续的，但ADC量化的数字值是离散的，因为这个映射关系导致的误差被称为量化误差，是量化误差带来了量化噪声

> ADC的信噪比反映了量化噪声的大小

最后还要考虑到集成电路无处不在的**热噪声**。由于电阻、MOSFET内部的电子热运动，会出现随机涨落的噪声电流。热噪声是一种典型的白噪声

我们一般将电路热噪声、运放引起的噪声、ADC量化噪声统称为**读出噪声**（因为运放和ADC噪声占主要部分，因此有时候也分开称为读出噪声和ADC噪声）。读出噪声符合高斯分布，功率谱密度几乎是频带内的一条水平线，呈现**白噪声**特点

### 信噪比

在上面一节，我们能得知**信号带噪声输出公式**：
$$
I=Lg +n_{read}g+n_{ADC}
$$
其中I表示Sensor的像素数字量输出，L表示光电传感器（APS）的输出电平，g是与ISO增益有关的设置值常量，$n_{read}$​表示读出噪声，$n_{ADC}$表示ADC量化噪声。这里面读出噪声和ADC噪声都符合高斯分布，而原始电压则符合泊松分布

其中
$$
L \sim \pi(t(\alpha \Phi +D);n_{read} \sim N(0,\sigma_{read});n_{ADC} \sim N(0,\sigma_{ADC})
$$
由于读出噪声和ADC量化噪声都符合高斯分布，可以把式子简化为**仿射噪声模型**
$$
I=Lg +n_{add},n_{add}=n_{read}g+n_{ADC} \sim N(0,\sqrt{\sigma_{read}^2 g^2 +\sigma_{ADC}^2})
$$
其中$n_{add}$被称为**加性噪声**——因为它看上去就像是一个偏置值，直接加在Lg参数上

结合之前的介绍，根据公式可知：

- 场景很亮时，光散粒噪声起主导作用
- 场景很暗时，暗噪声起主导作用，曝光时间越长，暗噪声影响越大
- 光散粒噪声和输入信号绑定在一起，无法消除
- 低ISO值时，ADC噪声更突出，而高ISO值时，光散粒噪声和读出噪声更突出

因为暗噪声的存在，像素的原始值并不绝对反映场景的亮度；且暗噪声是最难去除的——拍摄多张图像并取均值的方法可以有效减轻遵循正态分布（高斯分布）的读出噪声和ADC噪声的影响，但对暗噪声于事无补。因此不如整体测量出噪声值再从最终信号中减去

> 在仿射噪声模型中，$n_{add}$被看作整体信号的偏置，所以可以独立去除；但暗噪声不一样，它是作为信号的“附加增益”存在的

得到了上面的结论，看似噪声和图像的曝光时间、受光亮正相关，但实际上图片噪声随光照的变化如下图所示，要解释这个问题就要引入**信噪比**的概念。

![v2-c224c9e4cbd2438da7f46e05193b656a_r](三维重建2【光学参数标定】.assets/v2-c224c9e4cbd2438da7f46e05193b656a_r.jpg)

信噪比SNR定义为信号功率和噪声功率的比值，一般用信号主频率分量的功率谱密度代表信号功率；背景噪声的功率谱密度代表噪声功率。我们用信噪比则反映了噪声相比信号的相对大小，当**噪声减小时其方差变小，而信噪比减大**。**图像的噪点多少实际上取决于信噪比的大小**

Sensor场景下，信噪比可以定义为
$$
SNR=\frac{E^2(I)}{\sigma^2(I)}=\frac{(\alpha t \Phi g)^2}{\alpha t \Phi g^2 +\sigma^2_{read} g^2 +\sigma^2_{ADC}}
$$
当**曝光时间t很大，或者场景很亮时**，我们可以忽略掉加性噪声部分，即
$$
SNR=\frac{(\alpha t \Phi g)^2}{\alpha t \Phi g^2 }=\alpha t \Phi
$$
这种情况下像素值越大，信噪比也越大，**噪声在图像中看起来越不明显**。这就是为什么强光环境下图像噪点会很少

反过来讲，如果曝光时间t很小，或者场景很暗时，光噪可以忽略，加性噪声占主导，有
$$
SNR=\frac{(\alpha t \Phi g)^2}{\sigma^2_{read} g^2 +\sigma^2_{ADC}}
$$
如果图像亮度保持不变，SNR的分子固定；ISO增大导致g增大，最后让SNR下降，噪声变明显

### 噪声标定

终于到了最后的解决噪声部分。在上一章的黑电平校正算法部分，我们略过了如何标定黑电平值，现在来介绍。

根据上面的介绍，**暗电流、读出噪声、ADC量化噪声、运放增益尺度**就是我们要标定并最终在图片中减去的值了。我们将它们分成暗噪声和加性噪声两部分处理。

暗噪声的处理非常难，因为我们并不知道g的具体值（这是一个与ISO成正比的常数），但考虑到加性噪声服从高斯分布且均值是0，根据中心极限定理，我们在有大量数据的情况下，可以看作加性噪声为0！这样就为求解暗噪声提供了方便

于是在停止曝光的情况下直接拍摄大量图像，再对这些图像取均值，相当于令Φ=0，求解E(I)，得到
$$
E(I)=tDg
$$
我们可以知道在一定ISO下（g不变）、一定曝光时间条件下的暗帧！这就意味着不求出暗电流D的具体值，只要在同等曝光时间和ISO设定的图像中减去这个暗帧，就可以直接消除图像中的暗噪声。在这个过程中我们需要做的就是**针对相机的不同ISO设置分别标定当前暗帧**

> 这便是在上一章中提到“减去预标定的带有暗电流的图像”的原因

不过由于ISP中常常使用自动曝光，就不太好针对每个曝光时间标定暗帧，因此可以利用暗噪声大小与曝光时长成正比，标定出一些典型ISO值后通过线性插值的方式来计算出中间ISO值的补偿比例即可

接下来处理加性噪声。在标定后，整个式子变得简单：
$$
\delta^2(I)=E(I)g+\sigma^2_{add}
$$
像素的方差与均值呈现出线性关系，这就方便通过取平均来补偿了。我们可以在特定增益g下拍摄大量灰阶图像，针对每张图像先减去当前暗帧后求每个像素均值的方差，并使用线性回归算法拟合出一条最符合的直线如下图所示

![v2-56b1545c44650ff30b256dfe4363b676_r](三维重建2【光学参数标定】.assets/v2-56b1545c44650ff30b256dfe4363b676_r.jpg)

这条直线的斜率就是增益g，截距则是加性噪声的方差$\sigma^2_{add}$

> 灰阶图像如下图所示
>
> ![image-20240207012053170](三维重建2【光学参数标定】.assets/image-20240207012053170.png)
>
> 其目的就是为不同位置的像素提供不同的亮度值，方便获得均值-方差图表

这样，我们就能够实现黑电平校正算法了。工业上的实现还要考虑一些细节，采用各种trick做处理，不再赘述

### 动态范围

**动态范围**（dynamic range）是可变化信号最大值和最小值的比值

在各种传感器中，动态范围都是重要的参数。图像领域，动态范围是指图像能捕捉的场景中光亮度的范围。这里的亮度指的是发光强度与发光面面积之比，单位坎德拉cd/m。

> 1cd等于频率为$540*10^{12}$​Hz的单色光源在给定方向单位立体角发出的光通量
>
> 发光面定义为垂直于光源发光指定方向的面

在上一章提到过自然场景中，最大亮度和最小亮度的比值可以高达10000:1，由于人眼和Sensor结构差别极大，人眼的动态范围可以动态调节，但Sensor的动态范围就只能在某个较小区间了。更糟糕的是ISP过程还会让Sensor的动态范围进一步缩小，导致相机的动态范围比Sensor的动态范围还要小一些

![v2-425eb6311bd0d9923423f824037cd96d_r](三维重建2【光学参数标定】.assets/v2-425eb6311bd0d9923423f824037cd96d_r.jpg)

那么如何进行高动态范围成像呢？上一章中介绍了使用Gamma函数对图像进行校正的方式，这在ISP中很常见，但对于专业的照相机需求远远不够。目前广泛使用的一种方法是通过多重曝光的图像合成，来生成高动态范围的图像，核心思想非常简单：**拍摄同一场景不同曝光度下的多张照片并将它们合理融合起来**

> 很好理解，一部分照片负责补足一段动态范围内的信息，从整体上建立一个更广的动态范围

首先要对图像进行Gamma校正，使用非线性图像恢复响应函数对图像像素做处理，让图片符合人眼感受。

需要用到基本对数函数
$$
g(f)=ln(f^{-1})
$$
代入相机成像函数
$$
z_{ij}=f(E_i \Delta t_j) \leftrightarrow f^{-1}(z_{ij})=E_i \Delta t_j 
$$
得到
$$
g(z_{ij})=ln(E_i) +ln(\Delta t_j)
$$
使用下面的公式让它作用到原始图像
$$
Z_{ij,lin}=exp(g(z_{ij}))
$$
即可

目前已知量是Z和t，未知量是场景的辐照度E和Gamma变换函数g。为求出g，可以在固定场景对着同一物体拍摄多张照片，这样就多了一个约束条件，即在多次拍摄时，E是不变的。再假设g是一个单调递增函数（*辐照度越强，图像亮度值越大*），且g是平滑的，那么我们可以通过下式求出未知量
$$
\O =\sum_{i=1}^N \sum_{j=1}^N [g(z_{ij}) -ln(E_i)-ln(\Delta t_j)]^2 +\lambda \sum_{z=Z_{min}+1}^{Z_{max}-1} g''(z)^2
$$
这是一个典型的最小二乘问题，可以直接计算得到g

考虑到多次拍摄过程中的加权融合，需要采用下列加权系数函数来确定每幅图的权重

![image-20240206185818330](三维重建2【光学参数标定】.assets/image-20240206185818330.png)

这就得到了HDR图像

## 相机成像模型





### 光学模型





### 变换和齐次坐标

为确定空间物体表面某点的三维几何位置与其在图像中对应点之间的相互关系，必须建立摄像机成像的几何模型。这些几何模型参数就是摄像机**参数**。在大多数条件下这些参数必须通过实验与计算才能得到，求解参数的过程就是相机**标定**。一般来说，需要标定的参数包括：**内参**、**外参**、**畸变**参数



在不考虑镜头畸变，将相机成像模型简化为小孔成像模型时，考虑世界坐标系中点$P(x_w,y_w,z_w)$，对应相机坐标系中坐标为$(x_c,y_c,z_c)$，而图像平面上对应点的坐标为$(u,v)$，三者满足
$$
\left[ \begin{matrix}
u\\
v\\
1\\
\end{matrix} \right]
=
\left[ \begin{matrix}
f_x&0&c_x\\
0&f_y&c_y\\
0&0&1\\
\end{matrix} \right]
\left[ \begin{matrix}
R&t\\
0&1\\
\end{matrix} \right]
\left[ \begin{matrix}
x_w\\
y_w\\
z_w\\
1\\
\end{matrix} \right]
$$
其中，$f_x$和$f_y$是相机焦距，$c_x$和$c_y$是图像平面的主点坐标，R代表旋转矩阵，t是平移向量



### 世界坐标和相机坐标

首先定义三个坐标系

* **世界坐标系**：用户定义的三维世界的坐标系，描述目标物在真实世界里的位置
* **图像坐标系**：以相机所采集二维图像的左上角为原点定义的坐标系，用于描述三维物体在相机中所成像的投影透射关系
* **相机坐标系**：以相机为原点建立的坐标系，从相机的角度描述物体位置，作为沟通世界坐标系和图像坐标系的中间一环

标定的过程分为两个部分：

1. 从世界坐标系转换为相机坐标系

    这一步本质是三维点到三维点的转换，标定后得到相机的**外参**

2. 从相机坐标系转为图像坐标系

    这是三维点到二维点的转换，标定后得到相机的**内参**

此外，由于相机光学系统制造工艺的误差，实际成像与理想成像存在几何失真，也就是畸变——这是我们不想看到的。这就需要使用畸变矫正算法对图像进行修正，在此之前也需要对**畸变参数**进行标定



坐标映射：世界坐标系 ——> 相机坐标系 ——> 图像坐标系

计算：内参、外参、畸变参数

### 外参

包含R和t矩阵

目标：实现三维点到三维点的转换

![image-20241017162822748](./三维重建2【光学参数标定】.assets/image-20241017162822748.png)





### 内参

包含K矩阵

目标：实现三维点（相机坐标系）到二维点（图像坐标系）映射

![image-20241017162857497](./三维重建2【光学参数标定】.assets/image-20241017162857497.png)







### 三角测量





### 本质矩阵





### 基础矩阵











## 相机内参标定







## 相机外参标定





## 从立体校正到立体匹配





### 立体校正





### 立体匹配



