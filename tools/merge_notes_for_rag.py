#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# generated by LLM
"""
Markdownæ–‡ä»¶åˆå¹¶å·¥å…· - ä¸“ä¸ºçŸ¥è¯†åº“å¯¼å…¥è®¾è®¡
å°†å½“å‰ç›®å½•åŠå­ç›®å½•ä¸­çš„æ‰€æœ‰Markdownæ–‡ä»¶åˆå¹¶ä¸ºå•ä¸€æ–‡ä»¶
"""

import os
import argparse
from pathlib import Path
import logging
from typing import List, Set

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('merge_notes.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class MarkdownMerger:
    def __init__(self, output_file: str = "merge_notes_for_rag.md", 
                 max_size_mb: float = 10.0, exclude_dirs: Set[str] = None,
                 exclude_files: Set[str] = None):
        """
        åˆå§‹åŒ–åˆå¹¶å™¨
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶å
            max_size_mb: æœ€å¤§æ–‡ä»¶å¤§å°é™åˆ¶(MB)
            exclude_dirs: è¦æ’é™¤çš„ç›®å½•é›†åˆ
            exclude_files: è¦æ’é™¤çš„æ–‡ä»¶é›†åˆ
        """
        self.output_file = output_file
        self.max_size_bytes = int(max_size_mb * 1024 * 1024)
        
        # é»˜è®¤è·³è¿‡çš„ç›®å½•
        default_skip_dirs = {
            'tools', '.vscode', '.git', 'node_modules', 'book', 
            '__pycache__', '.pytest_cache', 'dist', 'build'
        }
        self.exclude_dirs = default_skip_dirs.union(exclude_dirs or set())
        self.exclude_files = exclude_files or set()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.processed_files = 0
        self.skipped_files = 0
        self.total_size = 0
        self.error_files = []

    def should_skip_directory(self, dir_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡ç›®å½•"""
        return (dir_name.startswith('.') or 
                dir_name in self.exclude_dirs)

    def should_skip_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶"""
        if file_path.suffix.lower() != '.md':
            return True
        
        if file_path.name in self.exclude_files:
            return True
            
        # è·³è¿‡è¾“å‡ºæ–‡ä»¶æœ¬èº«
        if file_path.name == self.output_file:
            return True
            
        return False

    def collect_markdown_files(self, root_path: Path) -> List[Path]:
        """æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„Markdownæ–‡ä»¶"""
        md_files = []
        
        for root, dirs, files in os.walk(root_path):
            # è¿‡æ»¤æ‰è¦è·³è¿‡çš„ç›®å½•
            dirs[:] = [d for d in dirs if not self.should_skip_directory(d)]
            
            for file in files:
                file_path = Path(root) / file
                if not self.should_skip_file(file_path):
                    md_files.append(file_path)
        
        # æŒ‰è·¯å¾„æ’åºï¼Œç¡®ä¿è¾“å‡ºé¡ºåºä¸€è‡´
        return sorted(md_files)

    def read_file_content(self, file_path: Path) -> str:
        """å®‰å…¨è¯»å–æ–‡ä»¶å†…å®¹"""
        encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312']
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    return f.read()
            except UnicodeDecodeError:
                continue
            except Exception as e:
                logger.error(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                self.error_files.append(str(file_path))
                return ""
        
        logger.warning(f"æ— æ³•è§£ç æ–‡ä»¶ {file_path}ï¼Œè·³è¿‡å¤„ç†")
        self.error_files.append(str(file_path))
        return ""

    def format_file_header(self, file_path: Path, relative_path: str) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤´éƒ¨ä¿¡æ¯"""
        separator = "=" * 80
        return f"""
{separator}
æ–‡ä»¶è·¯å¾„: {relative_path}
æ–‡ä»¶å: {file_path.name}
{separator}

"""

    def merge_files(self, root_path: Path = None) -> bool:
        """åˆå¹¶æ‰€æœ‰Markdownæ–‡ä»¶"""
        if root_path is None:
            root_path = Path('.')
        
        logger.info(f"å¼€å§‹æ‰«æç›®å½•: {root_path.absolute()}")
        md_files = self.collect_markdown_files(root_path)
        
        if not md_files:
            logger.warning("æœªæ‰¾åˆ°ä»»ä½•Markdownæ–‡ä»¶")
            return False
        
        logger.info(f"æ‰¾åˆ° {len(md_files)} ä¸ªMarkdownæ–‡ä»¶")
        
        try:
            with open(self.output_file, 'w', encoding='utf-8', newline='\n') as output:
                # å†™å…¥æ–‡ä»¶å¤´
                output.write(f"""# åˆå¹¶çš„Markdownç¬”è®°æ–‡ä»¶

> æœ¬æ–‡ä»¶ç”± merge_notes_for_rag.py è‡ªåŠ¨ç”Ÿæˆ
> ç”Ÿæˆæ—¶é—´: {self._get_current_time()}
> åŒ…å«æ–‡ä»¶æ•°é‡: {len(md_files)}

---

""")
                
                current_size = len(output.getvalue().encode('utf-8')) if hasattr(output, 'getvalue') else 0
                
                for i, file_path in enumerate(md_files, 1):
                    try:
                        # æ˜¾ç¤ºè¿›åº¦
                        print(f"\rå¤„ç†è¿›åº¦: {i}/{len(md_files)} ({i/len(md_files)*100:.1f}%)", end='', flush=True)
                        
                        # è¯»å–æ–‡ä»¶å†…å®¹
                        content = self.read_file_content(file_path)
                        if not content.strip():
                            self.skipped_files += 1
                            continue
                        
                        # è®¡ç®—ç›¸å¯¹è·¯å¾„
                        try:
                            relative_path = file_path.relative_to(root_path)
                        except ValueError:
                            relative_path = file_path
                        
                        # æ ¼å¼åŒ–è¾“å‡ºå†…å®¹
                        file_header = self.format_file_header(file_path, str(relative_path))
                        formatted_content = f"{file_header}{content}\n\n"
                        
                        # æ£€æŸ¥æ–‡ä»¶å¤§å°é™åˆ¶
                        content_size = len(formatted_content.encode('utf-8'))
                        if current_size + content_size > self.max_size_bytes:
                            logger.warning(f"è¾¾åˆ°æ–‡ä»¶å¤§å°é™åˆ¶ ({self.max_size_bytes/1024/1024:.1f}MB)ï¼Œåœæ­¢æ·»åŠ æ–‡ä»¶")
                            break
                        
                        # å†™å…¥å†…å®¹
                        output.write(formatted_content)
                        current_size += content_size
                        self.processed_files += 1
                        self.total_size += content_size
                        
                    except Exception as e:
                        logger.error(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                        self.error_files.append(str(file_path))
                        self.skipped_files += 1
                        continue
                
                print()  # æ¢è¡Œ
                
        except Exception as e:
            logger.error(f"å†™å…¥è¾“å‡ºæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
        
        return True

    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def print_statistics(self):
        """æ‰“å°å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*60)
        print("å¤„ç†ç»Ÿè®¡ä¿¡æ¯:")
        print(f"æˆåŠŸå¤„ç†æ–‡ä»¶æ•°: {self.processed_files}")
        print(f"è·³è¿‡æ–‡ä»¶æ•°: {self.skipped_files}")
        print(f"é”™è¯¯æ–‡ä»¶æ•°: {len(self.error_files)}")
        print(f"æ€»æ–‡ä»¶å¤§å°: {self.total_size/1024/1024:.2f} MB")
        print(f"è¾“å‡ºæ–‡ä»¶: {self.output_file}")
        
        if self.error_files:
            print("\né”™è¯¯æ–‡ä»¶åˆ—è¡¨:")
            for error_file in self.error_files:
                print(f"  - {error_file}")
        
        print("="*60)

def main():
    parser = argparse.ArgumentParser(
        description="åˆå¹¶Markdownæ–‡ä»¶ç”¨äºçŸ¥è¯†åº“å¯¼å…¥",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python merge_notes_for_rag.py
  python merge_notes_for_rag.py -o my_notes.md
  python merge_notes_for_rag.py --max-size 5 --exclude-dir temp
  python merge_notes_for_rag.py --exclude-file README.md LICENSE.md
        """
    )
    
    parser.add_argument(
        '-o', '--output',
        default='merge_notes_for_rag.md',
        help='è¾“å‡ºæ–‡ä»¶å (é»˜è®¤: merge_notes_for_rag.md)'
    )
    
    parser.add_argument(
        '--max-size',
        type=float,
        default=200.0,
        help='æœ€å¤§æ–‡ä»¶å¤§å°é™åˆ¶(MB) (é»˜è®¤: 10.0)'
    )
    
    parser.add_argument(
        '--exclude-dir',
        action='append',
        help='è¦æ’é™¤çš„ç›®å½• (å¯å¤šæ¬¡ä½¿ç”¨)'
    )
    
    parser.add_argument(
        '--exclude-file',
        action='append', 
        help='è¦æ’é™¤çš„æ–‡ä»¶ (å¯å¤šæ¬¡ä½¿ç”¨)'
    )
    
    parser.add_argument(
        '--root-path',
        default='.',
        help='æ‰«æçš„æ ¹ç›®å½•è·¯å¾„ (é»˜è®¤: å½“å‰ç›®å½•)'
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆå¹¶å™¨å®ä¾‹
    merger = MarkdownMerger(
        output_file=args.output,
        max_size_mb=args.max_size,
        exclude_dirs=set(args.exclude_dir or []),
        exclude_files=set(args.exclude_file or [])
    )
    
    # æ‰§è¡Œåˆå¹¶
    logger.info("å¼€å§‹åˆå¹¶Markdownæ–‡ä»¶...")
    success = merger.merge_files(Path(args.root_path))
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    merger.print_statistics()
    
    if success:
        logger.info(f"åˆå¹¶å®Œæˆï¼è¾“å‡ºæ–‡ä»¶: {args.output}")
        print(f"\nâœ… åˆå¹¶æˆåŠŸï¼æ–‡ä»¶å·²ä¿å­˜ä¸º: {args.output}")
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(args.output)/1024/1024:.2f} MB")
        print("ğŸš€ ç°åœ¨å¯ä»¥å°†æ­¤æ–‡ä»¶å¯¼å…¥åˆ°çŸ¥è¯†åº“ä¸­")
    else:
        logger.error("åˆå¹¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯")
        print("\nâŒ åˆå¹¶å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ merge_notes.log")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())